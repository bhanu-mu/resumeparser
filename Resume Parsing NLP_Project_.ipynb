{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dideLKUHk-m7"
   },
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20578,
     "status": "ok",
     "timestamp": 1641235181595,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "jSmvaht4rqut",
    "outputId": "007aeb3a-1018-4965-ff33-d927ca9057b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (1.21.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (from PyPDF2) (3.10.0.2)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (20220524)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (from pdfminer.six) (37.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Requirement already satisfied: docx2txt in c:\\users\\bhanupriya\\anaconda3\\lib\\site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n",
    "!pip install PyPDF2\n",
    "!pip install pdfminer.six\n",
    "!pip install docx2txt\n",
    "!pip install plotly\n",
    "!pip install cufflinks\n",
    "!pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1641235444819,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "Hz0N1ERyk-m8",
    "outputId": "39f213e4-4a94-4b2a-80b8-293383a827be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanupriya\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Bhanupriya\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Bhanupriya\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing required modules\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter  #process_pdf\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import re\n",
    "from io import StringIO\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import io\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import docx2txt\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import plotly.express as px\n",
    "import os\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkKrTDcqk-m_"
   },
   "source": [
    "# 2. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HX6vTYe1k-nA"
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "mypath = 'demoresume.docx'\n",
    "def extract_text_from_doc(doc_path):\n",
    "    temp = docx2txt.process(doc_path)\n",
    "    text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "    return ' '.join(text)\n",
    "\n",
    "resume_data=extract_text_from_doc(mypath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFXPpb28k-nH"
   },
   "source": [
    "# 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YgAutAoLk-nH"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1641026173732,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "fhQH95v3k-nI",
    "outputId": "a39c602c-1415-4b51-fe57-12822127be90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     An existing connection was forcibly closed by the\n",
      "[nltk_data]     remote host>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZQin28w4k-nJ"
   },
   "outputs": [],
   "source": [
    "more_stop_words = ['\\x0c','\"','-','_','.']\n",
    "stop_words.extend(more_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Prkp2jlk-nJ"
   },
   "source": [
    "clean_data() takes sentence separated string input and cleans the data i.e. removing stopwords and punctuation and returning lemmetized string output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XM_SK0jSk-nJ"
   },
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    re.sub(r'[\\d]','',text)\n",
    "    re.sub(r'[^a-zA-Z]','',text)\n",
    "    re.sub('\\s+',' ',text)\n",
    "    text_clean = []\n",
    "    text_tokens = word_tokenize(text)\n",
    "     \n",
    "    for word in text_tokens:\n",
    "        if (word not in stop_words and \n",
    "            word not in string.punctuation): \n",
    "            stem_word = lemmetizer.lemmatize(word) \n",
    "            text_clean.append(stem_word)\n",
    "    \n",
    "    list_to_str = ' '.join([str(ele) for ele in text_clean])\n",
    "    return list_to_str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZMUxau_k-nK"
   },
   "source": [
    "call_to_clean() takes full text as input, breaks them into sentences and calls the clean_data() with the separated sentences as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "swgzVAybk-nK"
   },
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "def call_to_clean(text):\n",
    "    sentences = re.split(r'\\n+',text)\n",
    "    sentence_df = pd.DataFrame(sentences, columns = ['Text'])\n",
    "    sentence_df['Text'] = sentence_df['Text'].apply(clean_data)\n",
    "    clean_text.append(' '.join(sentence_df['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2123,
     "status": "ok",
     "timestamp": 1641026175837,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "jIVO9d0Hk-nL",
    "outputId": "3f560380-91e1-4997-d5ce-a23c1cd9897f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "call_to_clean(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1641026175838,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "IZUt43EU2fHb",
    "outputId": "350f1bfc-3e45-469f-cbed-de4e299d1825"
   },
   "outputs": [],
   "source": [
    "clean_text=clean_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1IxwXWhk-nL"
   },
   "source": [
    "### Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CgkaS52ZQoH"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_60HddM3Jqux"
   },
   "source": [
    "# 1.Name extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D69kgo4Al0nN"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', [pattern], None)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text\n",
    "\n",
    "name =extract_name(clean_text)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1641026190163,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "4KS5zrm6dnI1",
    "outputId": "1f74f736-26ee-405b-aed4-60fcc58c1658"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'praveen kumar'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "parsed_data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data[\"Name\"]=pd.Series(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j94me1YKJ_g6"
   },
   "source": [
    "# 2.Mobile Number Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "flsFwzRCl0p_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mobile_number(text):\n",
    "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
    "    \n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    "        if len(number) > 10:\n",
    "            return '+' + number\n",
    "        else:\n",
    "            return number\n",
    "\n",
    "mobile =extract_mobile_number(clean_text)\n",
    "mobile\n",
    "parsed_data['Mobile']=pd.Series(mobile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrSnwOMAKMVp"
   },
   "source": [
    "# 3.Email-Id Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "mhLZwqUgJmKR"
   },
   "outputs": [],
   "source": [
    "def extract_email(email):\n",
    "    email = re.findall(\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\", email)\n",
    "    if email:\n",
    "        try:\n",
    "            return email[0].split()[0].strip(';')\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "# Calling the function \n",
    "email = extract_email(resume_data)\n",
    "parsed_data['Email']=pd.Series(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1641026190812,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "Na3kNSvuYSlj",
    "outputId": "cb0ac92f-dd52-4a52-86d8-720053369df9"
   },
   "outputs": [],
   "source": [
    "skills=pd.read_csv('skills.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>technical skills</th>\n",
       "      <th>ajenti</th>\n",
       "      <th>django-suit</th>\n",
       "      <th>django-xadmin</th>\n",
       "      <th>flask-admin</th>\n",
       "      <th>flower</th>\n",
       "      <th>grappelli</th>\n",
       "      <th>wooey</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>...</th>\n",
       "      <th>virtualized networks</th>\n",
       "      <th>network automation</th>\n",
       "      <th>cloud management</th>\n",
       "      <th>ai</th>\n",
       "      <th>salesforce</th>\n",
       "      <th>mango db</th>\n",
       "      <th>math</th>\n",
       "      <th>calculus</th>\n",
       "      <th>product launch</th>\n",
       "      <th>mvp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 1250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, technical skills, ajenti, django-suit, django-xadmin, flask-admin, flower, grappelli, wooey, algorithms, pypattyrn, python-patterns, sortedcontainers, django-simple-captcha, django-simple-spam-blocker, django-compressor, django-pipeline, django-storages, fanstatic, fileconveyor, flask-assets, jinja-assets-compressor, webassets, audiolazy, audioread, beets, dejavu, django-elastic-transcoder, eyed3, id3reader, m3u8, mingus, pyaudioanalysis, pydub, pyechonest, talkbox, timeside, tinytag, authomatic, django-allauth, django-oauth-toolkit, flask-oauthlib, oauthlib, python-oauth2, python-social-auth, rauth, sanction, jose, pyjwt, python-jws, python-jwt, bitbake, buildout, platformio, pybuilder, scons, django-cms, djedi-cms, feincms, kotti, mezzanine, opps, plone, quokka, wagtail, widgy, beaker, diskcache, django-cache-machine, django-cacheops, django-viewlet, dogpile.cache, hermescache, johnny-cache, pylibmc, errbot, coala, code2flow, pycallgraph, flake8, pylama, pylint, mypy, asciimatics, cement, click, cliff, clint, colorama, docopt, gooey, python-fire, python-prompt-toolkit, aws-cli, bashplotlib, caniusepython3, cookiecutter, doitlive, howdoi, httpie, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1250 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDik433WYV52"
   },
   "source": [
    "# 4.Skills Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7yNv4hofXnWd"
   },
   "outputs": [],
   "source": [
    "from pyresparser import ResumeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "wEVXJwOnX0RJ"
   },
   "outputs": [],
   "source": [
    "data_skills = ResumeParser('demoresume.docx').get_extracted_data()['skills']\n",
    "data_skills= ','.join([str(ele) for ele in data_skills])\n",
    "data_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641026201878,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "iHUz5KTQXbNx",
    "outputId": "0a19b000-1c9a-473b-dc05-9e20c91d7285"
   },
   "outputs": [],
   "source": [
    "parsed_data['Skills']=pd.Series(data_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Email</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>praveen kumar</td>\n",
       "      <td>9704379358</td>\n",
       "      <td>praveen.goshika@musquaretech.com</td>\n",
       "      <td>Sublime,Engagement,Apis,Ui,Design,Mobile,Postg...</td>\n",
       "      <td>Bachelors Degree (B.Tech) from Avanthi  Engine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name      Mobile                             Email  \\\n",
       "0  praveen kumar  9704379358  praveen.goshika@musquaretech.com   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Sublime,Engagement,Apis,Ui,Design,Mobile,Postg...   \n",
       "\n",
       "                                           Education  \n",
       "0  Bachelors Degree (B.Tech) from Avanthi  Engine...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pc26TFZeiKYo"
   },
   "source": [
    "# 5.Education Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "j9OkV_2XiIdB"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Grad all general stop words\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# Education Degrees\n",
    "EDUCATION = [\n",
    "            'BE','B.E.', 'B.E', 'BS','Bachelor of Technology','Senior Secondary' 'B.S', 'B.SC', 'B E', 'B. E.','B. E','B S','B. S','B. SC'\n",
    "            'ME', 'M.E', 'M.E.', 'MS', 'M.S', 'B-TECH','M-TECH','M E', 'M. E','B.COM','B.ED','L.L.B.','LLB','LLM','L.L.M.', 'M. E.', 'M S', 'M. S',\n",
    "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH','B TECH', 'B. TECH', 'M. TECH', 'M TECH',\n",
    "            'B. TECH','M. TECH','B TECH','M TECH','M.D.','NDA','N.D.A.','PHD','PGDM','P.G.D.M.' 'MBA','M.B.A.','MCA','M.C.A.','MS','M.S.','MD',\n",
    "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII',\n",
    "            'BBA','B.B.A.','BCA','B.C.A.','BA','B.A.', \n",
    "        ]\n",
    "\n",
    "\n",
    "education = []\n",
    "def extract_education(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "\n",
    "    # Sentence Tokenizer\n",
    "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
    "\n",
    "    edu = {}\n",
    "    # Extract education degree\n",
    "    for index, text in enumerate(nlp_text):\n",
    "        for tex in text.split():\n",
    "            # Replace all special symbols\n",
    "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "            if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
    "                edu[tex] = text + nlp_text[index]   \n",
    "\n",
    "    # Extract year\n",
    "    education = []\n",
    "    if edu:\n",
    "        for key in edu.keys():\n",
    "            year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])  \n",
    "            if year:\n",
    "                education.append((key, ''.join(year[0])))\n",
    "            else:\n",
    "                education.append(key)\n",
    "        return education\n",
    "    else:\n",
    "        EDU_PATTERN = re.findall(r'Bachelors? \\D+|Masters? \\D+',resume_text)   \n",
    "        return EDU_PATTERN\n",
    "        \n",
    "\n",
    "# Calling function\n",
    "education = extract_education(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1641026362775,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "L-w95nuwkjEG",
    "outputId": "babe2487-c40e-4d86-b886-0693dc278a74"
   },
   "outputs": [],
   "source": [
    "parsed_data['Education']=pd.Series(education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7lmKaPvQ4dW"
   },
   "source": [
    "# 6.Extracting Years of Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "xwOvp-dNV1L6"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "0DwYYDx_iIfe"
   },
   "outputs": [],
   "source": [
    "def extract_years_of_experience(text):\n",
    "    lines = sent_tokenize(text)           \n",
    "    experience = []\n",
    "    for sentence in lines:\n",
    "        if re.search('experience',sentence.lower()):        \n",
    "            sen_tokenized = nltk.word_tokenize(sentence)\n",
    "            tagged = nltk.pos_tag(sen_tokenized)            \n",
    "            entities = nltk.chunk.ne_chunk(tagged)          \n",
    "            for subtree in entities.subtrees():\n",
    "                for leaf in subtree.leaves():\n",
    "                    if leaf[1] == 'CD':                     \n",
    "                        experience.append(leaf[0])\n",
    "                        \n",
    "    exp = []\n",
    "    for ele in experience:\n",
    "        if len(ele) <=4  or (len(ele) <= 4 and ele[-1] == '0'\n",
    "                                and ele not in ('2020','2010','2000')):       \n",
    "            exp.append(ele)\n",
    "    if exp:\n",
    "        return exp[0]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1641026362779,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "NMGIXyG0WOCJ",
    "outputId": "c3969c7f-b091-4f70-d6b5-0309c1416b50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Bhanupriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from pyresparser import ResumeParser\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1641026362779,
     "user": {
      "displayName": "rahul mehra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsVgLxydk1UwJM-g0PDcp0yWyrALaChn88FsqoFA=s64",
      "userId": "15596182711114112626"
     },
     "user_tz": -330
    },
    "id": "oril-c2blEvb",
    "outputId": "695bbae5-e702-4f7c-d62d-dd018f9f73e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Bhanupriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Bhanupriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "NV_UlrTjYPpo"
   },
   "outputs": [],
   "source": [
    "years_of_experience = []\n",
    "\n",
    "years_of_experience.append(extract_years_of_experience(resume_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data['Experience']=pd.Series(years_of_experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OB-UZVQZimE"
   },
   "source": [
    "# 7.Extraction of Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Q_rA1oO_Y6U_"
   },
   "outputs": [],
   "source": [
    "links = []\n",
    "def extract_links(text):\n",
    "    x = re.findall(r'(https://(www.)?[a-z]+.com(/in)?/[a-z0-9]+)',text)   \n",
    "    links = []\n",
    "    for strings in x:\n",
    "        for link in strings:\n",
    "            if len(link) > 4:\n",
    "                links.append(link)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "D_8a3VdBl0sw"
   },
   "outputs": [],
   "source": [
    "links=extract_links(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data['links']=pd.Series(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Email</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Education</th>\n",
       "      <th>Experience</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>praveen kumar</td>\n",
       "      <td>9704379358</td>\n",
       "      <td>praveen.goshika@musquaretech.com</td>\n",
       "      <td>Sublime,Engagement,Apis,Ui,Design,Mobile,Postg...</td>\n",
       "      <td>Bachelors Degree (B.Tech) from Avanthi  Engine...</td>\n",
       "      <td>3yrs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name      Mobile                             Email  \\\n",
       "0  praveen kumar  9704379358  praveen.goshika@musquaretech.com   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Sublime,Engagement,Apis,Ui,Design,Mobile,Postg...   \n",
       "\n",
       "                                           Education Experience  links  \n",
       "0  Bachelors Degree (B.Tech) from Avanthi  Engine...       3yrs    NaN  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Name\":{\"0\":\"praveen kumar\"},\"Mobile\":{\"0\":\"9704379358\"},\"Email\":{\"0\":\"praveen.goshika@musquaretech.com\"},\"Skills\":{\"0\":\"Sublime,Engagement,Apis,Ui,Design,Mobile,Postgresql,Javascript,Outreach,Safety,Testing,Sql,Access,Analysis,Api,Github,Html,Android,Engineering,Controls,Programming,Visual,Health,System,Ai,Css,Healthcare,Database,Website,Js,Technical,Cloud,Windows\"},\"Education\":{\"0\":\"Bachelors Degree (B.Tech) from Avanthi  Engineering College in \"},\"Experience\":{\"0\":\"3yrs\"},\"links\":{\"0\":null}}'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_json=parsed_data.to_json()\n",
    "parsed_json"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mjnSd6mgk-nN",
    "huECy2pNk-nP",
    "YZilzvtqk-nP",
    "fI3oA8zsk-nQ",
    "JpOBWdh1k-nR",
    "p0wcgolPk-nR",
    "thDy_oQ_k-nR",
    "4dTjyTdlk-nS",
    "YFly12Gdk-nS",
    "3TICm10bk-nU",
    "GsF9dm5dk-nV",
    "n34nE1Gok-nV",
    "QBCkewvTk-nW",
    "sdMGd4gwk-nW",
    "HQYyHBdbk-nW",
    "o5V3RxNIk-nX",
    "0crsXWvzk-nX",
    "VsGmHZWqk-nY",
    "CisSPEZpk-nY"
   ],
   "name": "Resume Parsing NLP_Project_.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
